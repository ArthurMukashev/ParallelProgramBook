<!DOCTYPE html>
  <head>
    <title>Интерактивный учебник</title>
    <meta name="keywords" content="" />
	<meta name="description" content="" />
    <!-- 
    Polygon Template
    https://templatemo.com/tm-400-polygon
    -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="css/templatemo_misc.css">
    <link href="css/templatemo_style.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Raleway:400,100,600' rel='stylesheet' type='text/css'>
      
    <script src="js/jquery-1.10.2.min.js"></script> 
	<script src="js/jquery.lightbox.js"></script>
	<script src="js/templatemo_custom.js"></script>
    <script>
    function showhide()
    {
    	var div = document.getElementById("newpost");
		if (div.style.display !== "none")
		{
			div.style.display = "none";
		}
		else {
			div.style.display = "block";
		}
    }
  	</script>
  </head>
  <body>
  	<div class="site-header">
		<div class="main-navigation">
			<div class="responsive_menu">
				<ul>
					<li><a href="index.html">На главную</a></li>
				</ul>
			</div>
			<div class="container">
				<div class="row templatemo_gallerygap">
					<div class="col-md-12 responsive-menu">
						<a href="#" class="menu-toggle-btn">
				            <i class="fa fa-bars"></i>
				        </a>
					</div> <!-- /.col-md-12 -->
                    <div class="col-md-3 col-sm-12">
                    	<a href="index.html"><img src="images/templatemo_logo.png" alt="Polygon HTML5 Template"></a>
                    </div>
					<div class="col-md-9 main_menu">
						<ul>
							<li><a href="index.html">
                            	<span class="fa fa-book"></span>
                                На главную</a></li>
						</ul>
					</div> <!-- /.col-md-12 -->
				</div> <!-- /.row -->
			</div> <!-- /.container -->
		</div> <!-- /.main-navigation -->
	</div> <!-- /.site-header -->
    <div id="menu-container">
    <!-- gallery start -->
     <div class="container">
		 <h2>14. Использование MPI.</h2>
		 <a class="fa fa-book" href="https://ru.wikipedia.org/wiki/Message_Passing_Interface"> Источник 1</a>
		 |
		 <a class="fa fa-book" href="http://parallel.uran.ru/node/182"> Источник 2</a>
		 |
		 <a class="fa fa-book" href="https://habr.com/ru/post/121925/"> Источник 3</a>

		 <p><b>Message Passing Interface</b> (MPI, интерфейс передачи сообщений) — программный интерфейс (API) для передачи информации, который позволяет обмениваться сообщениями между процессами, выполняющими одну задачу. Разработан Уильямом Гроуппом, Эвином Ласком (англ.) и другими.</p>
		 <p>MPI является наиболее распространённым стандартом интерфейса обмена данными в параллельном программировании, существуют его реализации для большого числа компьютерных платформ. Используется при разработке программ для кластеров и суперкомпьютеров. Основным средством коммуникации между процессами в MPI является передача сообщений друг другу.</p>
		 <p>Стандартизацией MPI занимается MPI Forum. В стандарте MPI описан интерфейс передачи сообщений, который должен поддерживаться как на платформе, так и в приложениях пользователя. В настоящее время существует большое количество бесплатных и коммерческих реализаций MPI. Существуют реализации для языков Фортран 77/90, Java, Си и C++.</p>
		 <p>В первую очередь MPI ориентирован на системы с распределенной памятью, то есть когда затраты на передачу данных велики, в то время как OpenMP ориентирован на системы с общей памятью (многоядерные с общим кешем). Обе технологии могут использоваться совместно, чтобы оптимально использовать в кластере многоядерные системы.</p>
		 <p>Первая версия MPI разрабатывалась в 1993—1994 году, и MPI 1 вышла в 1994.</p>
		 <p>Большинство современных реализаций MPI поддерживают версию 1.1. Стандарт MPI версии 2.0 поддерживается большинством современных реализаций, однако некоторые функции могут быть реализованы не до конца.</p>
		 <p>В MPI 1.1 (опубликован 12 июня 1995 года, первая реализация появилась в 2002 году) поддерживаются следующие функции:</p>
		 <ul>
			 <li>передача и получение сообщений между отдельными процессами;</li>
			 <li>коллективные взаимодействия процессов;</li>
			 <li>взаимодействия в группах процессов;</li>
			 <li>реализация топологий процессов;</li>
		 </ul>
		 <p>В MPI 2.0 (опубликован 18 июля 1997 года) дополнительно поддерживаются следующие функции:</p>
		 <ul>
			 <li>динамическое порождение процессов и управление процессами;</li>
			 <li>односторонние коммуникации (Get/Put);</li>
			 <li>параллельный ввод и вывод;</li>
			 <li>расширенные коллективные операции (процессы могут выполнять коллективные операции не только внутри одного коммуникатора, но и в рамках нескольких коммуникаторов).</li>
		 </ul>
		 <p>Версия MPI 2.1 вышла в начале сентября 2008 года.</p>
		 <p>Версия MPI 2.2 вышла 4 сентября 2009 года.</p>
		 <p>Версия MPI 3.0 вышла 21 сентября 2012 года.</p>
		 <h4>Функционирование интерфейса</h4>
		 <p>Базовым механизмом связи между MPI процессами является передача и приём сообщений. Сообщение несёт в себе передаваемые данные и информацию, позволяющую принимающей стороне осуществлять их выборочный приём:</p>
		 <ul>
			 <li>отправитель — ранг (номер в группе) отправителя сообщения;</li>
			 <li>получатель — ранг получателя;</li>
			 <li>признак — может использоваться для разделения различных видов сообщений;</li>
			 <li>коммуникатор — код группы процессов.</li>
		 </ul>
		 <p>Операции приёма и передачи могут быть блокирующимися и неблокирующимися. Для неблокирующихся операций определены функции проверки готовности и ожидания выполнения операции.</p>
		 <p>Другим способом связи является удалённый доступ к памяти (RMA), позволяющий читать и изменять область памяти удалённого процесса. Локальный процесс может переносить область памяти удалённого процесса (внутри указанного процессами окна) в свою память и обратно, а также комбинировать данные, передаваемые в удалённый процесс с имеющимися в его памяти данными (например, путём суммирования). Все операции удалённого доступа к памяти не блокирующиеся, однако, до и после их выполнения необходимо вызывать блокирующиеся функции синхронизации.</p>
		 <h4>Пример программы</h4>
		 <pre>Вычисление числа Пи на языке C с использованием MPI:
// Подключение необходимых заголовков
#include&#60stdio.h>
#include&#60math.h>
// Подключение заголовочного файла MPI
#include "mpi.h"
 // Функция для промежуточных вычислений
double f (double a)
{
return (4.0 / (1.0+ a*a));
}
 // Главная функция программы
int main (intargc, char **argv)
{
    // Объявлениепеременных
int done = 0, n, myid, numprocs, i;
double PI25DT = 3.141592653589793238462643;
doublemypi, pi, h, sum, x;
doublestartwtime = 0.0, endwtime;
intnamelen;
charprocessor_name[MPI_MAX_PROCESSOR_NAME];
// Инициализация подсистемы MPI
MPI_Init(&argc, &argv);
// Получить размер коммуникатора MPI_COMM_WORLD
// (общее число процессов в рамках задачи)
MPI_Comm_size(MPI_COMM_WORLD,&numprocs);
// Получить номер текущего процесса в рамках
// коммуникатора MPI_COMM_WORLD
MPI_Comm_rank(MPI_COMM_WORLD,&myid);
MPI_Get_processor_name(processor_name,&namelen);
// Вывод номера потока в общем пуле
fprintf(stdout, "Process %d of %d is on %s\n", myid,numprocs,processor_name);
fflush(stdout);
while(!done)
    {
// количество интервалов
if(!myid)
        {
fprintf(stdout, "Enter the number of intervals: (0 quits) ");
fflush(stdout);
if(!scanf("%d",&n))
            {
fprintf(stdout, "No number entered; quitting\n");
n = 0;
            }
startwtime = MPI_Wtime();
        }
// Рассылка количества интервалов всем процессам (в том числе и себе)
MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);
if(!n) done = 1;
else
        {
            h = 1.0 / (double) n;
sum = 0.0;
// Обсчитывание точки, закрепленной за процессом
 for(i = myid + 1; (i <= n); i += numprocs)
      {
         x = h * ((double)i - 0.5);
		 sum += f(x);
      }
mypi = h * sum;
// Сброс результатов со всех процессов и сложение
MPI_Reduce(&mypi, &pi, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);
// Если это главный процесс, вывод полученного результата
if(!myid)
            {
printf("PI is approximately %.16f, Error is %.16f\n", pi, fabs(pi - PI25DT));
endwtime = MPI_Wtime();
printf("wall clock time =%f\n", endwtime-startwtime);
fflush(stdout);
            }
        }
    }
     // Освобождениеподсистемы MPI
MPI_Finalize();
return 0;
}</pre>
		 <h4>Реализации MPI</h4>
		 <p><b>MPICH</b> — одна из самых первых свободная реализация MPI, работает на UNIX-системах и Windows NT.</p>
		 <p><b>Open MPI</b> — ещё одна свободная реализация MPI. Основана на более ранних проектах FT-MPI, LA-MPI, LAM/MPI и PACX-MPI. Поддерживаются различные коммуникационные системы (в том числе Myrinet).</p>
		 <p><b>WMPI</b> — реализация MPI для Windows</p>
		 <p><b>MPI/PRO for Windows NT</b> — коммерческая реализация для Windows NT</p>
		 <p><b>Intel MPI</b> — коммерческая реализация для Windows / Linux</p>
		 <p><b>Microsoft MPI</b> входит в состав Compute Cluster Pack SDK. Основан на MPICH2, но включает дополнительные средства управления заданиями. Поддерживается спецификация MPI-2.</p>
		 <p><b>HP-MPI</b> — коммерческая реализация от HP</p>
		 <p><b>SGI MPT</b> — платная библиотека MPI от SGI</p>
		 <p><b>Mvapich</b> — свободная реализация MPI для Infiniband</p>
		 <p><b>Oracle HPC ClusterTools</b> — бесплатная реализация для Solaris SPARC/x86 и Linux на основе Open MPI</p>
		 <p><b>MPJ</b> — MPI for Java</p>
	 </div>
      <!-- gallery end -->


	<!-- footer start -->
    <div class="templatemo_footer">
    	<div class="container">
    	<div class="row">
        	<div class="col-md-9 col-sm-12">
            	<span>MukashevCorp &copy; 2019 OSPU | MOAIS</span>
            </div>
            <div class="col-md-3 col-sm-12 templatemo_rfooter">
            	  <a href="https://vk.com/art_m_m">
                 	<div class="hex_footer">
					<span class="fa fa-facebook"></span>
					</div>
                  </a>
            </div>
        </div>
        </div>
    </div>
    <!-- footer end -->    
	<script>
	$('.gallery_more').click(function(){
		var $this = $(this);
		$this.toggleClass('gallery_more');
		if($this.hasClass('gallery_more')){
			$this.text('Показать больше');
		} else {
			$this.text('Показать меньше');
		}
	});
    </script>
	<!-- templatemo 400 polygon -->
  </body>
</html>